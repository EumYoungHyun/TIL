### 추천시스템 정확도 판단 (MSE, RMSE, MAE)

검증력을 수학적으로 판단하는 방법이 있다.  
머신러닝의 모델을 최적화 하는데 사용되는 평가지표로서  
많이 사용되는건 MSE MAE RMSE들이고, 이중에서도 RMSE를 많이 사용한다

![MSE MAE RMSE](https://eumericano.s3.ap-northeast-2.amazonaws.com/dev/MSE%2C+MAE%2C+RMSE.png "MSE MAE RMSE")

코드 예시)

```python
import matplotlib
import numpy as np

def MSE(pred,target,epochs=len(pred)):
    losses=[]
    for i in range(epochs):
        losses.append(np.sum((pred[i]-target[i])**2)/len(pred))
    return losses

def RMSE(pred,target,epochs=len(pred)):
    losses=[]
    for i in range(epochs):
        losses.append(np.sqrt(np.sum((pred[i]-target[i])**2)/len(pred)))
    return losses

def MAE(pred,target,epochs=len(pred)):
    losses=[]
    for i in range(epochs):
        losses.append(np.sum(np.abs(pred[i]-target[i]))/len(pred))
    return losses

pred = np.array([[0,4,9],[2,4,2],[3,5,6]])
target = np.array([[3,5,7],[3,5,7],[3,5,7]])

print(MSE(pred,target))
print(RMSE(pred,target))
print(MAE(pred,target))

# outputs:
# [4.666666666666667, 9.0, 0.3333333333333333]
# [2.160246899469287, 3.0, 0.5773502691896257]
# [2.0, 2.3333333333333335, 0.3333333333333333]
```

1. MSE (Mean Squared Error, 평균 제곱 오차)  
   평균 제곱오차는 예측값과 정답과의 차이를 제곱하기 때문에 이상치에 민감하다.
   즉, 다른 데이터들은 비교적 비슷하더라도 하나의 큰 이상치가 있다면 그 값에 대해 민감하게 평가한다.  
   제곱이므로 소숫점의 차이는 더 작게 반영하는 특징이 있으며, 이차함수로서 첨점이 없고, 모든 점에서 미분 가능하다.

2. RMSE (Root Mean Squared Error, 평균 제곱근 오차)  
   평균 제곱근 오차는 MSE의 제곱근을 구하는 방식으로 MSE에 비해 비교적 큰차이에 덜 민감하다.  
   MSE에 루트를 취하기 때문에 일차함수 특징을 가지고 있고, 첨점이 있어 특정 지점에서는 미분 불가능하다.

3. MAE(Mean Absolute Error, 평균 절대값 오차)  
   평균 절대값 오차는 위 두가지 오차값과는 다르게 블랙스완에 강한 지표이다.  
   이 또한 절대값이므로 RMSE처럼 첨점이 있어 특정 지점에서는 미분이 불가능하고,  
   좀 더 디테일한 차이에 집중하는 느슨한 평가 지표가 될 수 있다.

이러한 측정들은 오프라인(개발환경)에서 평가하기 어렵다. 여기에는 다양한 견해들이 존재하는데  
일례로 2006년에 넷플릭스에서 추천알고리즘 개선에 현상금 100만 달러를 걸었다.  
이떄의 평가기준은 낮은 RMSE였는데, 넷플릭스도 가장 낮은 RMSE를 달성한 연구결과를 서비스에 반영하지 않았다.  
그 이유는 현실세계에서 고객의 사용 패턴을 보니 이는 별로 중요한 지표가 아니었음을 느꼈기 떄문이다.

중요한점은 단순히 낮은 지표를 기록하는게 아니라 사용자들이 클릭할만한 컨텐츠를 두는것이 더 바람직함을 깨닳았기 떄문이다.
